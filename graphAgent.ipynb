{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152c7b53-fb4e-4712-bb7b-4b2c3d25fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from typing import Annotated, TypedDict, Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2daaa81-b7e5-4928-b22d-eca310c4e160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load variables from the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21932b32-291b-40d9-92cf-aea913905c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7638c34a-24c3-4a83-9fcd-6a3e9f85f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Define the State\n",
    "class State(TypedDict):\n",
    "    # The add_messages reducer ensures new messages are appended, not overwritten\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# 2. Define the Node (The Logic)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, api_key=api_key)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a4189-8e84-41b9-b084-3f04acc2d7cc",
   "metadata": {},
   "source": [
    "### 1. Simple Persistent Agent (The \"Memory\" Test)\n",
    "This script allows you to chat with an agent, stop the cell, and restart it while retaining memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e916ec06-1c50-4aab-bfbe-25cc4e1dab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build the Graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Jupyter Implementation with Context Manager\n",
    "def run_simple_memory_test():\n",
    "    # 'checkpoints.db' saves to disk; ':memory:' stays in RAM\n",
    "    with SqliteSaver.from_conn_string(\"simple_checkpoints.db\") as memory:\n",
    "        app = builder.compile(checkpointer=memory)\n",
    "        \n",
    "        config = {\"configurable\": {\"thread_id\": \"amod_ds_001\"}}\n",
    "        \n",
    "        # Test 1: Introduction\n",
    "        print(\"--- Step 1 ---\")\n",
    "        for event in app.stream({\"messages\": [HumanMessage(content=\"Hi, I'm Amod, a Senior DS.\")]}, config, stream_mode=\"values\"):\n",
    "            if \"messages\" in event:\n",
    "                last_msg = event[\"messages\"][-1]\n",
    "                if last_msg.type == \"ai\":\n",
    "                    print(f\"ü§ñ: {last_msg.content}\")\n",
    "\n",
    "        # Test 2: Memory Check\n",
    "        print(\"\\n--- Step 2 ---\")\n",
    "        for event in app.stream({\"messages\": [HumanMessage(content=\"What is my name and seniority?\")]}, config, stream_mode=\"values\"):\n",
    "            if \"messages\" in event:\n",
    "                last_msg = event[\"messages\"][-1]\n",
    "                if last_msg.type == \"ai\":\n",
    "                    print(f\"ü§ñ: {last_msg.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3008e333-189c-4cc2-be58-7f851693d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1 ---\n",
      "ü§ñ: Hello Amod! As a Senior Data Scientist, you likely have a wealth of experience in data analysis, machine learning, and statistical modeling. If there's anything specific you'd like to discuss or explore, feel free to let me know!\n",
      "\n",
      "--- Step 2 ---\n",
      "ü§ñ: Your name is Amod, and you are a Senior Data Scientist.\n"
     ]
    }
   ],
   "source": [
    "run_simple_memory_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0378a189-31fb-48a6-b758-b8fa4490ed16",
   "metadata": {},
   "source": [
    "### 2. Multi-Step Tool Agent (The \"Agentic\" Test)\n",
    "This version includes the Router and ToolNode logic. It uses stream_mode=\"updates\" which is much cleaner for Jupyter as it labels which node produced which output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91249ef8-39e7-4372-aebe-1465b6e9c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, Literal\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# 1. Define Tool\n",
    "@tool\n",
    "def calculate_compute_budget(project_name: str):\n",
    "    \"\"\"Calculates the GPU compute budget for a specific AI project.\"\"\"\n",
    "    budgets = {\"project_alpha\": \"$50,000\", \"project_omega\": \"$120,000\"}\n",
    "    return f\"The budget for {project_name} is {budgets.get(project_name.lower(), 'not defined')}.\"\n",
    "\n",
    "tools = [calculate_compute_budget]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# 2. Setup Logic\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\",api_key=api_key).bind_tools(tools)\n",
    "\n",
    "def call_model(state: AgentState):\n",
    "    return {\"messages\": [model.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "\n",
    "def router(state: AgentState) -> Literal[\"tools\", END]:\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    # Check if it's an AI message AND if it has tool calls\n",
    "    if isinstance(last_msg, AIMessage) and last_msg.tool_calls:\n",
    "        return \"tools\"\n",
    "    # If it's a ToolMessage or a plain text AIMessage, we stop or go to next logic\n",
    "    return END\n",
    "\n",
    "# 3. Build Graph\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"agent\", call_model)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "builder.add_edge(START, \"agent\")\n",
    "builder.add_conditional_edges(\"agent\", router)\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# 4. Execute with Context Manager\n",
    "def run_agentic_workflow():\n",
    "    with SqliteSaver.from_conn_string(\"agentic_checkpoints.db\") as memory:\n",
    "        app = builder.compile(checkpointer=memory)\n",
    "        config = {\"configurable\": {\"thread_id\": \"agent_session_1\"}}\n",
    "        \n",
    "        query = \"What is the budget for project_omega?\"\n",
    "        print(f\"üöÄ User Query: {query}\\n\")\n",
    "        \n",
    "        # We use 'updates' to see exactly which node is firing\n",
    "        for output in app.stream({\"messages\": [HumanMessage(content=query)]}, config, stream_mode=\"updates\"):\n",
    "            for node_name, state_update in output.items():\n",
    "                print(f\"üìç [Node: {node_name}]\")\n",
    "                if \"messages\" in state_update:\n",
    "                    last_m = state_update[\"messages\"][-1]\n",
    "                    # Print tool calls or final text\n",
    "                    content = last_m.tool_calls if last_m.tool_calls else last_m.content\n",
    "                    print(f\"   Output: {content}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fac9fd7f-3389-4328-a10a-463d900c0fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ User Query: What is the budget for project_omega?\n",
      "\n",
      "üìç [Node: agent]\n",
      "   Output: The budget for project_omega is $120,000.\n"
     ]
    }
   ],
   "source": [
    "run_agentic_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29ea8d-3217-4073-abe7-e2941129c6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b55fc1-64be-4078-ab08-fa7b54c60b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95f433-480b-4c32-96b2-68b8cf1a703b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095a9fd5-7823-4a2f-a1a2-78a95215f0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d2f89-9ae1-4b6b-bc5d-ac4094de1e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa977851-feed-4504-97ad-dd46db797b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba373d53-378d-4ae8-8189-464613a5a5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6230358-1812-49a4-87c8-3eb0f8f32ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1800c-aceb-404f-9c16-a09a76fef58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04a3c4-b9f9-49eb-b07e-92e6adbf9238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71780dbc-d075-4a1d-967f-451184ee6de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee8e9e-2231-429b-a2fa-a817db7b914c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9408ab6-3a90-4aa5-ad04-96b344e8796e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ba09b-36fa-4784-ad79-51c8bbd00674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3480e5-8f2b-4dfc-b853-f9c950650515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72e3ba-3d58-4ae0-9095-e029c458f24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a306008-0163-475a-b306-58060146f508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd1772-f6ce-4323-87d1-5afc3c7a5029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0c6b0-c2d2-404b-89b2-6a27b6846cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7110aef-5c3d-4c92-bb5d-815abf8ef0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4242004-59b9-4389-a1ab-61b34747d5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f0581-bc90-4044-b10e-8d647c918155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b9d82-873e-428d-9ce2-507d36ff6679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c4582-0fc0-4125-b9c5-be35294e9357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e670b7-8cd0-4240-b642-237c9c45a1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a373aa-06ce-4a61-90a8-cde18a6fd89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c9124-4707-4c05-90ef-86c64f6ac73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf65200-aea4-44ac-b5d2-d95107996e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29270c7-0add-47fd-a0c6-341246533497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24953047-8970-4f3e-bd57-44cc5176cf39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d498504a-3374-4f8e-8e63-4a0f8762f266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1344e0-1652-42a4-8a4e-613f1d39db19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae4914a-4123-422e-a469-db4d42d2285b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e520db0-1af0-4a61-837d-776309c020ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51a512-f10a-450d-8265-4e7c00ddb17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5892d574-fb00-4b93-84fb-03e3550c7415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ac124-1f10-4503-ba27-e1a8bb129014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306c653-4cba-4841-ab09-58cfa50e61c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990e30f-3d1a-4a66-9d6c-0747381f82d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39947338-88b0-408a-95ef-307ccdd87d56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph",
   "language": "python",
   "name": "langraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
